{
    "embed_dim": 768,
    "vision_cfg": {
        "image_size": 224,
        "layers": 12,
        "width": 768,
        "head_width": 64,
        "patch_size": 16,
        "mlp_ratio": 4,
        "drop_path_rate": 0.0,
        "xattn": true,
        "fusedLN": true,
        "rope": true,
        "pt_hw_seq_len": 16,
        "intp_freq": true,
        "naiveswiglu": true,
        "subln": true
    },
    "text_cfg": {
        "internvl_model_name": "/mnt/pfs-guan-ssai/cv/cjy/models/chinese_alpaca_lora_7b",
        "internvl_tokenizer_name": "/mnt/pfs-guan-ssai/cv/cjy/models/chinese_alpaca_lora_7b",
        "pooler_type": "mean_pooler",
        "proj": "mlp",
        "context_length": 80,
        "vocab_size": 49954,
        "width": 4096,
        "heads": 32,
        "layers": 32,
        "xattn": true,
        "fusedLN": true
    }
}